# 操作 browser 的 API
from selenium.webdriver.chrome.service import Service
from selenium import webdriver

# 處理逾時例外的工具
from selenium.common.exceptions import TimeoutException

# 面對動態網頁，等待某個元素出現的工具，通常與 exptected_conditions 搭配
from selenium.webdriver.support.ui import WebDriverWait

# 搭配 WebDriverWait 使用，對元素狀態的一種期待條件，若條件發生，則等待結束，往下一行執行
from selenium.webdriver.support import expected_conditions as EC

# 期待元素出現要透過什麼方式指定，通常與 EC、WebDriverWait 一起使用
from selenium.webdriver.common.by import By

# 強制等待 (執行期間休息一下)
from time import sleep

import csv

# send_keys模擬鍵盤輸入
from selenium.webdriver.common.keys import Keys

import random

import re

# listening
import pyautogui
from time import sleep, time
import keyboard
from IPython.display import clear_output

# 多執行緒
import threading



def initialize_browser():
    # 啟動瀏覽器工具的選項
    my_options = webdriver.ChromeOptions()
    # my_options.add_argument("--headless")                #不開啟實體瀏覽器背景執行
    my_options.add_argument("--start-maximized")         #最大化視窗
    my_options.add_argument("--incognito")               #開啟無痕模式
    my_options.add_argument("--disable-popup-blocking") #禁用彈出攔截
    my_options.add_argument("--disable-notifications")  #取消 chrome 推播通知
    my_options.add_argument("--lang=zh-TW")  #設定為正體中文

    # 使用 Chrome 的 WebDriver
    driver = webdriver.Chrome(
        options = my_options
    )

    return driver


def input_name(driver, search_name):
    # 前往google_map網站
    driver.get('https://www.google.com/maps?authuser=0')

    # 尋找網頁中的搜尋框
    input_block = driver.find_element(
        By.CSS_SELECTOR,
        'input.searchboxinput.xiQnY'
    )
    print(f'{search_name}-starting...')
    # 在搜尋框中輸入文字
    input_block.send_keys(f'松山區{search_name} 飲料店')
    sleep(0.1)
    input_block.send_keys(Keys.ENTER)
    sleep(0.5)


def scroll(driver):
    innerHeight = 0
    offset = 0
    count = 0
    start = True

    # google_map，JS動態變化前標籤
    inner_frame = WebDriverWait(driver, 10).until(
        EC.presence_of_element_located(
            (By.CSS_SELECTOR, "div.m6QErb.DxyBCb.kA9KIf.dS8AEf.ecceSd > div.m6QErb.DxyBCb.kA9KIf.dS8AEf.ecceSd"))
    )

    offset = driver.execute_script(
        '''return document.querySelector('div.m6QErb.DxyBCb.kA9KIf.dS8AEf.ecceSd > div.m6QErb.DxyBCb.kA9KIf.dS8AEf.ecceSd').scrollHeight;'''
    )

    # 使用 JavaScript 來捲動內部視窗的滾動條
    driver.execute_script(f'''
            document.querySelector("div.m6QErb.DxyBCb.kA9KIf.dS8AEf.ecceSd > div.m6QErb.DxyBCb.kA9KIf.dS8AEf.ecceSd").scrollTo({{
                top: {offset},
                behavior: 'smooth'
            }});
        ''')

    sleep(1)

    while start:

        offset = driver.execute_script(
            "return document.querySelector('div.m6QErb.DxyBCb.kA9KIf.dS8AEf.ecceSd.QjC7t').scrollHeight;"
        )

        # google_map，JS動態變化後標籤
        inner_frame = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "div.m6QErb.DxyBCb.kA9KIf.dS8AEf.ecceSd.QjC7t"))
        )

        # 使用 JavaScript 來捲動內部視窗的滾動條
        driver.execute_script(f'''
                document.querySelector("div.m6QErb.DxyBCb.kA9KIf.dS8AEf.ecceSd.QjC7t").scrollTo({{
                    top: {offset},
                    behavior: 'smooth'
                }});
            ''')

        # 強制休息
        sleep(random.randrange(4))

        inner_height = driver.execute_script(
            '''return document.querySelector('div.m6QErb.DxyBCb.kA9KIf.dS8AEf.ecceSd > div.m6QErb.DxyBCb.kA9KIf.dS8AEf.ecceSd').scrollHeight;'''
        )


        # 網頁滾到最底，結束程式
        if inner_height == offset:
            print(count)
            if count in [4, 6]:
                                
                # 往回滾動，重新loading...
                offset = -20
                driver.execute_script(f'''
                    document.querySelector("div.m6QErb.DxyBCb.kA9KIf.dS8AEf.ecceSd.QjC7t").scrollBy({{
                        top: {offset},
                        behavior: 'smooth'
                        }});
                    ''')
                
                sleep(3)
            count += 1
        else:
            count = 0

        if count == 10:
            start = False


def scraping(driver):
    # 放置爬取的資料
    dataset = [['id', 'name', 'star', 'comment', 'class', 'coordinate', 'address']]

    # 取得google_map基本內容
    elements = driver.find_elements(
        By.CSS_SELECTOR,
        'div.UaQhfb.fontBodyMedium '
    )

    id = 0  # 店家id

    for elm in elements:
        # 店家id
        id += 1

        # 店家名稱
        name = elm.find_element(
            By.CSS_SELECTOR,
            'div.qBF1Pd.fontHeadlineSmall '
        )

        # 店家種類
        shop_class = elm.find_elements(
            By.CSS_SELECTOR,
            'div.W4Efsd > div.W4Efsd > span'
        )

        # 有些店家沒有評論數、星數，直接給數值為0
        no_commend = elm.find_element(
            By.CSS_SELECTOR,
            'span.e4rVHe.fontBodyMedium'
        )

        if no_commend.text == '沒有評論':
            dataset.append([id, name.text, 0, 0, shop_class[0].text])
            continue

        # 星數
        star = elm.find_element(
            By.CSS_SELECTOR,
            'span.MW4etd'
        )

        # 評論數
        comment_num = elm.find_element(
            By.CSS_SELECTOR,
            'span.UY7F9'
        )

        regex_comment = r"\w+"  # (60) => 60
        comment_num_re = re.search(regex_comment, comment_num.text)

        # 資料匯入list
        dataset.append([id, name.text, eval(star.text), eval(comment_num_re[0]), shop_class[0].text])


    # 取得各店家連結、經緯度
    list_links = [] # 存放店家連結

    links = driver.find_elements(
        By.CSS_SELECTOR,
        'a.hfpxzc'
    )

    id = 0

    for lelm in links:
        # 店家連結
        id += 1
        link = lelm.get_attribute('href')
        list_links.append(link)

        # coordinate(經緯度)
        regex_coordinate = r"(?<=!3d).*(?=!16s)"  # link => 25.0266645!4d121.5431999
        search_coordinate = re.search(regex_coordinate, link)
        coordinate = search_coordinate[0].replace('!4d', ',')  # coordinate:座標(經緯度)

        # 經緯度加入list
        dataset[id].append(coordinate)

    # 進入店家連結取得詳細資料
    id = 0

    for url in list_links:
        driver.get(url)

        # 強制休息
        sleep(random.randrange(4))
        
        id += 1

        # 詳細地址
        # address = driver.find_element(
        #     By.CSS_SELECTOR,
        #     'div.Io6YTe.fontBodyMedium.kR99db '
        # )
        address = WebDriverWait(driver, 10).until(
        EC.presence_of_element_located(
            (By.CSS_SELECTOR, "div.Io6YTe.fontBodyMedium.kR99db"))
        )

        regex_address = r'[^0-9].*'  # 106台北市大安區復興南路二段206號 => 台北市大安區復興南路二段206號
        search_address = re.search(regex_address, address.text)
        
        # 加入list
        dataset[id].append(search_address[0])

    return dataset

def to_csv(search_name, dataset):
    # 將 list 存成 csv
    with open(f"./{search_name}.csv", "w", newline='', encoding="utf-8-sig") as file:
        w = csv.writer(file)
        # 寫入二維表格
        w.writerows(dataset)
        print(f'{search_name}-ending...')

def listening():
    global switch

    while switch:
        # 睡一下
        sleep(0.01)

        #自動清除此格的文字輸出
        clear_output(wait=True)

        try:
            # 取得 Box 物件
            btn_reload = pyautogui.locateOnScreen(
                './reload.png',
                confidence=0.9 # opencv信心指數，用 1 的話圖片一點灰塵污漬都不能有 
            )

            btn_reload_point = pyautogui.center(btn_reload)

            # 按下 重新載入
            pyautogui.click(btn_reload_point.x, btn_reload_point.y)
        except:
            pass

if __name__ == "__main__":
    driver = initialize_browser()
    switch = True
    listening_thread = threading.Thread(target=listening)
    listening_thread.start()

    with open(r'./dist_test.txt', 'r', encoding='utf-8') as file:
        dist_list = file.read().split('、')  # 行政區
        for search_name in dist_list:
            search_name = search_name.strip() # 去除字串頭尾空格
            input_name(driver, search_name)
            scroll(driver)
            dataset = scraping(driver)
            to_csv(search_name, dataset)
            
    switch = False # 爬蟲結束，結束監聽   
    listening_thread.join() # 等待監聽線程结束
    
    driver.quit()